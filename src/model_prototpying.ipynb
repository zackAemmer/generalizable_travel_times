{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from database import data_utils, data_loader, model_utils\n",
    "from models import basic_rnn\n",
    "import run_models\n",
    "\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(basic_rnn)\n",
    "importlib.reload(data_loader)\n",
    "\n",
    "\n",
    "run_folder = \"../results/throwaway/\"\n",
    "fold_num = 0\n",
    "network_folder = \"kcm/\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Given sequence of bus data, predict average speed at next step\n",
    "# Next step can be current -> next gps coordinate\n",
    "# Should also benchmark with arima?\n",
    "# Can do single or multi step prediction\n",
    "# Can do fixed or variable sequence inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Loading data from '../results/throwaway/kcm/deeptte_formatted/'...\n",
      "Loading and merging GTFS files from './data/kcm_gtfs/2020_09_23/'...\n",
      "==============================\n",
      "FOLD: 0\n",
      "Successfully loaded 21589 training samples and 5391 testing samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct dataloaders for Pytorch models\n",
    "importlib.reload(data_loader)\n",
    "importlib.reload(basic_rnn)\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "### Set run and hyperparameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "LEARN_RATE = 1e-3\n",
    "HIDDEN_SIZE = 32\n",
    "\n",
    "### Load train/test data\n",
    "print(\"=\"*30)\n",
    "data_folder = run_folder + network_folder + \"deeptte_formatted/\"\n",
    "print(f\"Loading data from '{data_folder}'...\")\n",
    "# Load config\n",
    "with open(data_folder + \"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "# Load GTFS-RT samples\n",
    "train_data_chunks, valid_data = data_utils.load_train_test_data(data_folder, config['n_folds'])\n",
    "# Load GTFS data\n",
    "print(f\"Loading and merging GTFS files from '{config['gtfs_folder']}'...\")\n",
    "gtfs_data = data_utils.merge_gtfs_files(\".\"+config['gtfs_folder'])\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(f\"FOLD: {fold_num}\")\n",
    "# Set aside the train/test data according to the current fold number\n",
    "test_data = train_data_chunks[fold_num]\n",
    "train_data = [x for i,x in enumerate(train_data_chunks) if i!=fold_num]\n",
    "# Combine the training data to single object\n",
    "train_data = list(itertools.chain.from_iterable(train_data))\n",
    "\n",
    "\n",
    "train_dataset = data_loader.make_sequence_dataset(train_data, config)\n",
    "test_dataset = data_loader.make_sequence_dataset(test_data, config)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4)\n",
    "print(f\"Successfully loaded {len(train_data)} training samples and {len(test_data)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Training basic rnn model...\n",
      "EPOCH: 0\n",
      "here\n",
      "torch.Size([16, 1, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 16, 32), got [16, 1, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 32\u001b[0m\n\u001b[1;32m      6\u001b[0m embed_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeID\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[1;32m      8\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvocab_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1440\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     23\u001b[0m rnn_model \u001b[39m=\u001b[39m basic_rnn\u001b[39m.\u001b[39mBasicRNN(\n\u001b[1;32m     24\u001b[0m     train_dataloader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtensors[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],\n\u001b[1;32m     25\u001b[0m     \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     embed_dict\n\u001b[1;32m     29\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 32\u001b[0m rnn_train_losses, rnn_test_losses \u001b[39m=\u001b[39m model_utils\u001b[39m.\u001b[39;49mfit_to_data(rnn_model, train_dataloader, test_dataloader, LEARN_RATE, EPOCHS, device)\n\u001b[1;32m     33\u001b[0m torch\u001b[39m.\u001b[39msave(rnn_model\u001b[39m.\u001b[39mstate_dict(), run_folder \u001b[39m+\u001b[39m network_folder \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/rnn_model_\u001b[39m\u001b[39m{\u001b[39;00mfold_num\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m rnn_model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/valle/src/database/model_utils.py:50\u001b[0m, in \u001b[0;36mfit_to_data\u001b[0;34m(model, train_dataloader, test_dataloader, LEARN_RATE, EPOCHS, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m sequential_flag:\n\u001b[0;32m---> 50\u001b[0m     preds, hidden_prev \u001b[39m=\u001b[39m model(inputs, hidden_prev)\n\u001b[1;32m     51\u001b[0m     hidden_prev \u001b[39m=\u001b[39m hidden_prev\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/valle_m1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/valle/src/models/basic_rnn.py:48\u001b[0m, in \u001b[0;36mBasicRNN.forward\u001b[0;34m(self, x, hidden_prev)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Get recurrent pred\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(hidden_prev\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 48\u001b[0m out, hidden_prev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x_ct, hidden_prev)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Reshape, add context, combine with linear layer\u001b[39;00m\n\u001b[1;32m     51\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/valle_m1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/valle_m1/lib/python3.9/site-packages/torch/nn/modules/rnn.py:467\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    464\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    466\u001b[0m \u001b[39massert\u001b[39;00m hx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    468\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_RELU\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/valle_m1/lib/python3.9/site-packages/torch/nn/modules/rnn.py:232\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_input(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[1;32m    230\u001b[0m expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/valle_m1/lib/python3.9/site-packages/torch/nn/modules/rnn.py:226\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_hidden_size\u001b[39m(\u001b[39mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[1;32m    224\u001b[0m                       msg: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mExpected hidden size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(expected_hidden_size, \u001b[39mlist\u001b[39m(hx\u001b[39m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 16, 32), got [16, 1, 32]"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "importlib.reload(basic_rnn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(f\"Training basic rnn model...\")\n",
    "embed_dict = {\n",
    "    'timeID': {\n",
    "        'vocab_size': 1440,\n",
    "        'embed_dims': 24,\n",
    "        'col': 8\n",
    "    },\n",
    "    'weekID': {\n",
    "        'vocab_size': 7,\n",
    "        'embed_dims': 4,\n",
    "        'col': 9\n",
    "    },\n",
    "    'driverID': {\n",
    "        'vocab_size': config['n_unique_veh'],\n",
    "        'embed_dims': 12,\n",
    "        'col': 10\n",
    "    }\n",
    "}\n",
    "rnn_model = basic_rnn.BasicRNN(\n",
    "    train_dataloader.dataset.tensors[0][0].shape[2],\n",
    "    1,\n",
    "    HIDDEN_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    embed_dict\n",
    ").to(device)\n",
    "\n",
    "\n",
    "rnn_train_losses, rnn_test_losses = model_utils.fit_to_data(rnn_model, train_dataloader, test_dataloader, LEARN_RATE, EPOCHS, device)\n",
    "torch.save(rnn_model.state_dict(), run_folder + network_folder + f\"models/rnn_model_{fold_num}.pt\")\n",
    "rnn_model.eval()\n",
    "rnn_labels, rnn_preds = model_utils.predict(rnn_model, test_dataloader, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Epoch\": [x for x in range(0,len(ff_train_losses))],\n",
    "        \"Training Loss\": ff_train_losses,\n",
    "        \"Validation Loss\": ff_test_losses\n",
    "    }\n",
    ")\n",
    "sns.lineplot(x='Epoch', y='value', hue='variable', data=pd.melt(plot_data, ['Epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at predictions\n",
    "print(f\"MAPE: {metrics.mean_absolute_percentage_error(ff_labels, ff_preds)}\")\n",
    "print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(ff_labels, ff_preds))}\")\n",
    "print(f\"MAE: {metrics.mean_absolute_error(ff_labels, ff_preds)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valle_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b30fe1de1713ca8e7537eef068b13a2de77ded03f86aab2e80ea73416dd3d704"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
