{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938ddd2c-3533-480b-95d7-d5cffafc5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import time\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "import secret\n",
    "\n",
    "\n",
    "def connect_to_rds():\n",
    "    conn = psycopg2.connect(\n",
    "        host=secret.HOST,\n",
    "        database=secret.DATABASE,\n",
    "        user=secret.UID,\n",
    "        password=secret.PWD)\n",
    "    return conn\n",
    "\n",
    "def get_epoch_and_cet_24hr():\n",
    "    utc = datetime.utcnow()\n",
    "    cet = timedelta(hours=1)\n",
    "    current_hour = (utc + cet).hour\n",
    "    epoch = round(utc.timestamp())\n",
    "    return current_hour, epoch\n",
    "\n",
    "def xml_to_dict(element):\n",
    "    # Recursively create a dictionary of XML field -> text value\n",
    "    element_dict = {}\n",
    "    for child in element:\n",
    "        tag = re.split(\"}\", child.tag)[1]\n",
    "        if child.text != None:\n",
    "            element_dict[tag] = child.text\n",
    "        elif tag in element_dict.keys(): # In case multiple children with same tag exist in this element, make a list\n",
    "            if type(element_dict[tag]) == list:\n",
    "                element_dict[tag].append(xml_to_dict(child))\n",
    "            else:\n",
    "                first_elem = element_dict[tag]\n",
    "                element_dict[tag] = []\n",
    "                element_dict[tag].append(first_elem)\n",
    "        else:\n",
    "            element_dict[tag] = xml_to_dict(child)\n",
    "    return element_dict\n",
    "\n",
    "def exists_str_or_none(values, key):\n",
    "    if key in values.keys():\n",
    "        return str(values[key])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def clean_active_trips(vehicle_statuses):\n",
    "    to_remove = []\n",
    "    necessary_keys = ['FramedVehicleJourneyRef','VehicleLocation'] # The absolute minimum for useful data point\n",
    "    # Find indices of trips that are not monitored.\n",
    "    for i, vehicle in enumerate(vehicle_statuses):\n",
    "        try:\n",
    "            if vehicle['MonitoredVehicleJourney']['Monitored'] != 'true':\n",
    "                to_remove.append(i)\n",
    "            for key in necessary_keys:\n",
    "                if not key in vehicle['MonitoredVehicleJourney'].keys():\n",
    "                    to_remove.append(i)\n",
    "                    break\n",
    "        # If the requested value isn't found, except and remove\n",
    "        except:\n",
    "            to_remove.append(i)\n",
    "    # Remove inactive trips starting with the last index\n",
    "    for idx in sorted(to_remove, reverse=True):\n",
    "        del vehicle_statuses[idx]\n",
    "    return vehicle_statuses\n",
    "\n",
    "def upload_to_rds(to_upload, conn, collected_time):\n",
    "    to_upload_list = []\n",
    "    for vehicle_status in to_upload:\n",
    "        datedvehiclejourney = exists_str_or_none(vehicle_status['MonitoredVehicleJourney']['FramedVehicleJourneyRef'], 'DatedVehicleJourneyRef'), # JourneyPatternRef[1:3]-VehicleJourneyRef-??-JourneyPatternRef[4:6]-YYYYMMDD-????\n",
    "        dataframe = exists_str_or_none(vehicle_status['MonitoredVehicleJourney']['FramedVehicleJourneyRef'], 'DataFrameRef'),\n",
    "        vehicle = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'VehicleRef'),\n",
    "        mode = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'VehicleMode'),\n",
    "        line = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'LineRef'),\n",
    "        linename = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'PublishedLineName'),\n",
    "        direction = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'DirectionRef'),\n",
    "        operator = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'OperatorRef'),\n",
    "        datasource = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'DataSource'),\n",
    "        lat = exists_str_or_none(vehicle_status['MonitoredVehicleJourney']['VehicleLocation'], 'Latitude'),\n",
    "        lon = exists_str_or_none(vehicle_status['MonitoredVehicleJourney']['VehicleLocation'], 'Longitude'),\n",
    "        bearing = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'Bearing'),\n",
    "        delay = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'Delay'),\n",
    "        # nextstop = exists_str_or_none(vehicle_status['MonitoredVehicleJourney']['OnwardCalls']['OnwardCall'][0]['StopPointRef']),\n",
    "        locationtime = exists_str_or_none(vehicle_status['MonitoredVehicleJourney'], 'LocationRecordedAtTime'),\n",
    "        collectedtime = collected_time\n",
    "        to_upload_list.append((datedvehiclejourney, dataframe, vehicle, mode, line, linename, direction, operator, datasource, lat, lon, bearing, delay, locationtime, collectedtime))\n",
    "    with conn.cursor() as curs:\n",
    "        try:\n",
    "            args_str = ','.join(curs.mogrify('(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)', x).decode('utf-8') for x in to_upload_list)\n",
    "            query_str = 'INSERT INTO active_trips_norway (datedvehiclejourney, dataframe, vehicle, mode, line, linename, direction, operator, datasource, lat, lon, bearing, delay, locationtime, collectedtime) VALUES ' + args_str\n",
    "            curs.execute(query_str)\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            # Catch all errors and continue to keep server up and running\n",
    "            print(e)\n",
    "            conn.rollback()\n",
    "    return query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94feae8-9c1a-46c9-bed0-34ce06dbc340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1066\n"
     ]
    }
   ],
   "source": [
    "# Limited to 4 requests/minute, otherwise need publish/subscribe\n",
    "endpoint = 'https://api.entur.io/realtime/v1/rest/vm'\n",
    "conn = connect_to_rds()\n",
    "current_hour, current_epoch = get_epoch_and_cet_24hr()\n",
    "\n",
    "# Call Entur SIRI API (returns XML)\n",
    "response = requests.get(endpoint)\n",
    "root = ElementTree.fromstring(response.content)\n",
    "# root = ElementTree.parse('vm.xml').getroot()\n",
    "\n",
    "# Look at list of active vehicles from response\n",
    "root_dict = xml_to_dict(root)\n",
    "vehicle_statuses = root_dict['ServiceDelivery']['VehicleMonitoringDelivery']['VehicleActivity']\n",
    "print(len(vehicle_statuses))\n",
    "clean_active_trips(vehicle_statuses) # Modifies in-place by deleting elements\n",
    "print(len(vehicle_statuses))\n",
    "\n",
    "current_hour, current_epoch = get_epoch_and_cet_24hr()\n",
    "args_str = upload_to_rds(vehicle_statuses, conn, current_epoch)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b458cd3-ad31-45f7-aff3-1772c79bd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Better source for locationtime; convert to epoch\n",
    "# Possibly add back nextStop\n",
    "# Move to .py and start scraping\n",
    "# Possibly et more efficient types in DB instead of all varchar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
